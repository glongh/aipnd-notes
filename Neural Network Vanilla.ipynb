{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network (Structure)\n",
    "\n",
    "Plain vanilla (aka \"multiplayer perception\")\n",
    "\n",
    "![](images/neural_network_structure1.png)\n",
    "\n",
    "\n",
    "*__Neuron__*: Thing that holds a number (0 -> 1)\n",
    "\n",
    "*__Activation__*: The number inside the neuron\n",
    "\n",
    "![](images/neural_network_activation.png)\n",
    "\n",
    "Those 784 neurons represents the *__first layer__*\n",
    "\n",
    "![](images/neural_network_layer_last.png)\n",
    "\n",
    "Those 10 digits represents the *__last layer__*\n",
    "\n",
    "![](images/neural_network_concept_1.png)\n",
    "![](images/neural_network_concept_2.png)\n",
    "![](images/neural_network_concept_3.png)\n",
    "\n",
    "Want to fit numbers between 0-1 (signoid)  \n",
    "\n",
    "![](images/neural_network_concept_4.png)\n",
    "![](images/neural_network_concept_5.png)\n",
    "![](images/neural_network_concept_6.png)\n",
    "\n",
    "\n",
    "*__Bias__*: How hight high the weighted sum needs to be beore the neuron starts getting meaningfully active\n",
    "![](images/neural_network_concept_7.png)\n",
    "\n",
    "![](images/neural_network_learning_1.png)\n",
    "\n",
    "*__Learning__*: Getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.\n",
    "\n",
    "![](images/neural_network_computing.png)\n",
    "\n",
    "You can represent the transition between one layer to the other in a little tiny expression\n",
    "\n",
    "![](images/neural_network_computing_layer_transition.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient\n",
    "\n",
    "*__cost__*: It's small when the networt knows what it's doing and it's large when it doesn't\n",
    "\n",
    "Machine knows:\n",
    "![](images/neural_network_machine_knows.png)\n",
    "\n",
    "Machine does not knows:\n",
    "![](images/neural_network_machine_does_not_knows.png)\n",
    "\n",
    "\n",
    "We calculate the average cost of all the training data, and that measure how bad the computer should feel\n",
    "\n",
    "*__Neural network function__*\n",
    "\n",
    "![](images/neural_network_function.png)\n",
    "\n",
    "*__Neural network cost function__*\n",
    "![](images/neural_network_cost_function.png)\n",
    "\n",
    "*__Training data__*\n",
    "![](images/neural_network_training_data.png)\n",
    "![](images/neural_network_training_weights.png)\n",
    "![](images/neural_network_gradient_descent_1.png)\n",
    "![](images/neural_network_gradient_descent_2.png)\n",
    "![](images/neural_network_gradient_descent_3.png)\n",
    "![](images/neural_network_gradient_descent_4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "### Intuitive walkthrough\n",
    "\n",
    "*__Backprogation__*:  Is the algorithm for determinating how a single training example would like to nudge the weights and biases. Not just in terms of whether they should go up or down, but in terms of what relative proportions to those changes, cause the most rapid decrease to the cost.\n",
    "\n",
    "![](images/neural_network_training_1.png)\n",
    "\n",
    "\n",
    "A true *__gradient descent__* step, would involve doing this for all your tens and thousands of training examples\n",
    "\n",
    "![](images/neural_network_training_2.png)\n",
    "\n",
    "But that's computational slow, so instead, you randomly sub-divide the data into these mini-batches and compute each step with respect to a mini-batch\n",
    "\n",
    "![](images/neural_network_training_3.png)\n",
    "\n",
    "Repeatedly going through all of the mini-batches and making these adjustments, you will converge towards a local minimum of the cost function.\n",
    "\n",
    "![](images/neural_network_training_4.png)\n",
    "\n",
    "### Derivatives in computational graphs\n",
    "\n",
    "\n",
    "![](images/neural_network_chain_rule.png)\n",
    "\n",
    "![](images/neural_network_chain_rule_2.png)\n",
    "\n",
    "Multipying these 3 ratios gives the sencitivity of C to small changes in $w_(L)$\n",
    "![](images/neural_network_chain_rule_4.png)\n",
    "\n",
    "![](images/neural_network_chain_rule_3.png)\n",
    "\n",
    "![](images/neural_network_chain_rule_5.png)\n",
    "\n",
    "With multiple layers\n",
    "\n",
    "![](images/neural_network_multiple_1.png)\n",
    "\n",
    "![](images/neural_network_multiple_2.png)\n",
    "\n",
    "![](images/neural_network_multiple_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Gradient Descent\n",
    "\n",
    "#### Gradient Descent with Squared Errors\n",
    "We want to find the weights for our neural networks. Let's start by thinking about the goal. The network needs to make predictions as close as possible to the real values. To measure this, we use a metric of how wrong the predictions are, the error. A common metric is the sum of the squared errors (SSE):\n",
    "\n",
    "$$ E = \\frac{1}{2} \\sum_{\\mu} \\sum_{j} [y^\\mu_j - \\hat{y}^u_j]^2$$\n",
    "\n",
    "where $\\hat{y}$ is the prediction and $y$ is the true value, and you take the sum over all output units $j$ and another sum over all data points $\\mu$ \n",
    "\n",
    "First, the inside sum over $j$. This variable $j$ represents the output units of the network. So this inside sum is saying for each output unit, find the difference between the true value $y$ and the predicted value from the network $\\hat{y}$, then square the difference, then sum up all those squares.\n",
    "\n",
    "Then the other sum over $\\mu$ is a sum over all the data points. So, for each data point you calculate the inner sum of the squared differences for each output unit. Then you sum up those squared differences for each data point. That gives you the overall error for all the output predictions for all the data points.\n",
    "The *__SSE__* is a good choice for a few reasons. The square ensures the error is always positive and larger errors are penalized more than smaller errors.\n",
    "\n",
    "Remember that the output of a neural network, the prediction, depends on the weights\n",
    "\n",
    "$$ \\hat{y}^\\mu_j = f(\\sum_{i}w_{ij}x^\\mu_i) $$\n",
    "\n",
    "and accordingly the error depends on the weights\n",
    "\n",
    "$$ E = \\frac{1}{2}\\sum_{\\mu}\\sum_{j}[y^\\mu_j-f(\\sum_{i}w_{ij}x^\\mu_i)]^2$$ \n",
    "\n",
    "We want the network's prediction error to be as small as possible and the weights are the knobs we can use to make that happen. Our goal is to find weights $w_{ij}$ that minimize the squared error $E$. To do this with a neural network, typically you'd use *__gradient descent__*.\n",
    "\n",
    "With gradient descent, we take multiple small steps towards our goal. In this case, we want to change the weights in steps that reduce the error. Continuing the analogy, the error is our mountain and we want to get to the bottom. Since the fastest way down a mountain is in the steepest direction, the steps taken should be in the direction that minimizes the error the most. We can find this direction by calculating the gradient of the squared error.\n",
    "\n",
    "*__Gradient__* is another term for rate of change or slope.\n",
    "\n",
    "To calculate a rate of change, we turn to calculus, specifically derivatives. A derivative of a function $f(x)$ gives you another function $f'(x)$ that returns the slope of $f(x)$ at point $x$. For example, consider $f(x)=x^2$. The derivative of $x^2$ is $f'(x) = 2x$. So, at $x=2$, the slope is $f'(2)=4$. Plotting this out, it looks like:\n",
    "\n",
    "![](images/nn_gradient_descent_derivative_example_1.png)\n",
    "\n",
    "The gradient is just a derivative generalized to functions with more than one variable. We can use calculus to find the gradient at any point in our error function, which depends on the input weights. You'll see how the gradient descent step is derived on the next page.\n",
    "Below I've plotted an example of the error of a neural network with two inputs, and accordingly, two weights. You can read this like a topographical map where points on a contour line have the same error and darker contour lines correspond to larger errors.\n",
    "\n",
    "At each step, you calculate the error and the gradient, then use those to determine how much to change each weight. Repeating this process will eventually find weights that are close to the minimum of the error function, the black dot in the middle.\n",
    "\n",
    "![](images/nn_gradient_descent_steps_to_lower_error.png)\n",
    "\n",
    "#### Caveats\n",
    "Since the weights will just go wherever the gradient takes them, they can end up where the error is low, but not the lowest. These spots are called local minima. If the weights are initialized with the wrong values, gradient descent could lead the weights into a local minimum, illustrated below.\n",
    "\n",
    "![](images/nn_gradient_descent_local_minimum.png)\n",
    "\n",
    "\n",
    "\n",
    "![](images/SSE_2.png)\n",
    "\n",
    "SSE is a measure of the network's performance. If it's high, the network it's making bad predictions, if it's low the network it's making good predictions. We want to make as small as posible.\n",
    "\n",
    "![](images/SSE.png)\n",
    "![](images/SSE_3.png)\n",
    "![](images/SSE_4.png)\n",
    "![](images/SSE_5.png)\n",
    "\n",
    "#### Example with one data record / one output unit\n",
    "\n",
    "![](images/SSE_one_data.png)\n",
    "\n",
    "Subtituing for the prediction we see the error it's a fuction of the weights.\n",
    "\n",
    "![](images/SSE_gradient_concept.png)\n",
    "\n",
    "![](images/SSE_formula.png)\n",
    "\n",
    "### Formulas:\n",
    "\n",
    "![](images/GD_2.png)\n",
    "![](images/GD_3.png)\n",
    "![](images/GD_4.png)\n",
    "![](images/GD_5.png)\n",
    "![](images/GD_6.png)\n",
    "![](images/GD_8.png)\n",
    "![](images/GD_9.png)\n",
    "![](images/GD_10.png)\n",
    "![](images/GD_11.png)\n",
    "![](images/GD_12.png)\n",
    "![](images/GD_13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent: the code\n",
    "\n",
    "One weight update can be calculated as:\n",
    "\n",
    "$\\Delta w_i = \\eta \\delta x_i $\n",
    "\n",
    "with the error term $\\delta$ as\n",
    "\n",
    "$\\delta = (y - \\hat{y})f'(h) = (y-\\hat{y})f'(\\sum w_i x_i)$\n",
    "\n",
    "In the above equation $(y - \\hat{y})$ is the output error, and $f'(h)$ refers to the derivative of the activation function, $f(h)$. We'll call that derivative the output gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Defining the sigmoid function for activations\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Input data\n",
    "x = np.array([0.1, 0.3])\n",
    "# Target\n",
    "y = 0.2\n",
    "# Input to output weights\n",
    "weights = np.array([-0.8, 0.5])\n",
    "\n",
    "# The learning rate, eta in the weight step equation\n",
    "learnrate = 0.5\n",
    "\n",
    "# the linear combination performed by the node (h in f(h) and f'(h))\n",
    "h = x[0]*weights[0] + x[1]*weights[1]\n",
    "# or h = np.dot(x, weights)\n",
    "\n",
    "# The neural network output (y-hat)\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# output error (y - y-hat)\n",
    "error = y - nn_output\n",
    "\n",
    "# output gradient (f'(h))\n",
    "output_grad = sigmoid_prime(h)\n",
    "\n",
    "# error term (lowercase delta)\n",
    "error_term = error * output_grad\n",
    "\n",
    "# Gradient descent step \n",
    "del_w = [ learnrate * error_term * x[0],\n",
    "          learnrate * error_term * x[1]]\n",
    "# or del_w = learnrate * error_term * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network output:\n",
      "0.6899744811276125\n",
      "Amount of Error:\n",
      "-0.1899744811276125\n",
      "Change in Weights:\n",
      "[-0.02031869 -0.04063738 -0.06095608 -0.08127477]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consolidated, so there are\n",
    "###       fewer variable names than in the above sample code\n",
    "\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "h = np.dot(x, w)\n",
    "\n",
    "# TODO: Calculate output of neural network\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# TODO: Calculate error of neural network\n",
    "error = y - nn_output\n",
    "\n",
    "# TODO: Calculate the error term\n",
    "#       Remember, this requires the output gradient, which we haven't\n",
    "#       specifically added a variable for.\n",
    "\n",
    "\n",
    "# Note: The sigmoid_prime function calculates sigmoid(h) twice,\n",
    "#       but you've already calculated it once. You can make this\n",
    "#       code more efficient by calculating the derivative directly\n",
    "#       rather than calling sigmoid_prime, like this:\n",
    "error_term = error * nn_output * (1 - nn_output)\n",
    "\n",
    "# error_term = error * sigmoid_prime(h)\n",
    "\n",
    "\n",
    "# TODO: Calculate change in weights\n",
    "del_w = learnrate * error_term * x\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "This is how we update our weights:\n",
    "\n",
    "$ \\Delta w_ij = \\eta * \\delta * x_i' $\n",
    "\n",
    "We are going calculate the many weight updates so the network can learn.\n",
    "\n",
    "As an example, I'm going to have you use gradient descent to train a network on graduate school admissions data (found at http://www.ats.ucla.edu/stat/data/binary.csv). This dataset has three input features: GRE score, GPA, and the rank of the undergraduate school (numbered 1 through 4). Institutions with rank 1 have the highest prestige, those with rank 4 have the lowest.\n",
    "\n",
    "![](images/high_school_admission_data.png)\n",
    "\n",
    "The goal here is to predict if a student will be admitted to a graduate program based on these features. For this, we'll use a network with one output layer with one unit. We'll use a sigmoid function for the output unit activation.\n",
    "\n",
    "##### Data cleanup\n",
    "You might think there will be three input units, but we actually need to transform the data first. The rank feature is categorical, the numbers don't encode any sort of relative values. Rank 2 is not twice as much as rank 1, rank 3 is not 1.5 more than rank 2. Instead, we need to use dummy variables to encode rank, splitting the data into four new columns encoded with ones or zeros. Rows with rank 1 have one in the rank 1 dummy column, and zeros in all other columns. Rows with rank 2 have one in the rank 2 dummy column, and zeros in all other columns. And so on.\n",
    "\n",
    "We'll also need to standardize the GRE and GPA data, which means to scale the values such that they have zero mean and a standard deviation of 1. This is necessary because the sigmoid function squashes really small and really large inputs. The gradient of really small and large inputs is zero, which means that the gradient descent step will go to zero too. Since the GRE and GPA values are fairly large, we have to be really careful about how we initialize the weights or the gradient descent steps will die off and the network won't train. Instead, if we standardize the data, we can initialize the weights easily and everyone is happy.\n",
    "\n",
    "This is just a brief run-through, you'll learn more about preparing data later. If you're interested in how I did this, check out the data_prep.py file in the programming exercise below.\n",
    "\n",
    "![](images/high_school_admission_data_10.png)\n",
    "\n",
    "Now that the data is ready, we see that there are six input features: `gre`, `gpa`, and the four `rank` dummy variables.\n",
    "\n",
    "#### Mean Square Error\n",
    "We're going to make a small change to how we calculate the error here. Instead of the SSE, we're going to use the mean of the square errors (MSE). Now that we're using a lot of data, summing up all the weight steps can lead to really large updates that make the gradient descent diverge. To compensate for this, you'd need to use a quite small learning rate. Instead, we can just divide by the number of records in our data, \n",
    "m\n",
    "m to take the average. This way, no matter how much data we use, our learning rates will typically be in the range of 0.01 to 0.001. Then, we can use the MSE (shown below) to calculate the gradient and the result is the same as before, just averaged instead of summed.\n",
    "\n",
    "$$ E = \\frac{1}{2m} \\sum_{\\mu} (y^\\mu - \\hat{y}^u)^2$$\n",
    "\n",
    "The general algorithm for updating the weights with gradient descent:\n",
    "* Set the weight step to zero: $\\Delta w_i = 0$\n",
    "* For each record in the training data:\n",
    "    * Make a forward pass through the network, calculating the output $\\hat{y} = f(\\sum_i w_ix_i)$\n",
    "    * Calculate the error term for the output unit, $\\delta = (y - \\hat{y}) * f'(\\sum_i w_i x_i)$\n",
    "    * Update the weight step $\\Delta w_i = \\Delta w_i + \\delta x_i$\n",
    "    \n",
    "* Update the weights $w_i = w_i + \\mu \\Delta w_i  /  m$ where $\\mu$ is the learning rate and $m$ is the number of records. Here we are averaging the weight steps to help reduce any large variations in the training data.\n",
    "\n",
    "* Repeat for $e$ epochs.\n",
    "\n",
    "You can also update the weights on each record instead of averaging the weight steps after going through all the records.\n",
    "\n",
    "Remember that we're using the sigmoid for the activation function, $f(h) = 1/(1+e^{-h})$\n",
    "\n",
    "And the gradient of the sigmoid is $f'(h) = f(h)(1-f(h))$\n",
    "where $h$ is the input to teh output unit,\n",
    "\n",
    "$h = \\sum_i w_i x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing with NumPy\n",
    "\n",
    "First, initialize the weights. We want these to be small such that the input to the sigmoid is in the linear region near 0 and not squashed at the high and low ends. It's also important to initialize them randomly so that they all have different starting values and diverge, breaking symmetry. So, we'll initialize the weights from a normal distribution centered at 0. A good value for the scale is $1/\\sqrt{n}$ \n",
    "\n",
    "where $n$ is the number of input units. This keeps the input to the sigmoid low for increasing numbers of input units.\n",
    "\n",
    "```\n",
    "weights = np.random.normal(scale=1/n_features**.5, size=n_features)\n",
    "```\n",
    "\n",
    "Numpy provides a function `np.dot()` that calculates the dot product of two arrays, which conveniently calculates $h$ for us. \n",
    "\n",
    "```\n",
    "# input to the output layer\n",
    "output_in = np.dot(weights, inputs)\n",
    "```\n",
    "\n",
    "Finally, we can update $\\Delta w_i$ and $w_i$ by incrementing them with \n",
    "```\n",
    "weights += ...\n",
    "``` \n",
    "\n",
    "*__Efficiency note__*\n",
    "You can save some calculations since we're using a sigmoid here. For the sigmoid function, \n",
    "\n",
    "$$f'(h) = f(h)(1-f(h))$$\n",
    "\n",
    "That means that once you calculate $f(h)$, the activation of the output unit, you can use it to calculate the gradient for the error gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.26276093849966364\n",
      "Train loss:  0.20928619409324895\n",
      "Train loss:  0.20084292908073417\n",
      "Train loss:  0.1986215647552789\n",
      "Train loss:  0.19779851396686018\n",
      "Train loss:  0.19742577912189863\n",
      "Train loss:  0.19723507746241065\n",
      "Train loss:  0.19712945625092465\n",
      "Train loss:  0.19706766341315077\n",
      "Train loss:  0.19703005801777368\n",
      "Prediction accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# TODO: We haven't provided the sigmoid_prime function like we did in\n",
    "#       the previous lesson to encourage you to come up with a more\n",
    "#       efficient solution. If you need a hint, check out the comments\n",
    "#       in solution.py from the previous lecture.\n",
    "\n",
    "# Use to same seed to make debugging easier\n",
    "np.random.seed(42)\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Initialize weights\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # Loop through all records, x is the input, y is the target\n",
    "\n",
    "        # Activation of the output unit\n",
    "        #   Notice we multiply the inputs and the weights here \n",
    "        #   rather than storing h as a separate variable \n",
    "        output = sigmoid(np.dot(x, weights))\n",
    "\n",
    "        # The error, the target minus the network output\n",
    "        error = y - output\n",
    "\n",
    "        # The error term\n",
    "        #   Notice we calulate f'(h) here instead of defining a separate\n",
    "        #   sigmoid_prime function. This just makes it faster because we\n",
    "        #   can re-use the result of the sigmoid function stored in\n",
    "        #   the output variable\n",
    "        error_term = error * output * (1 - output)\n",
    "\n",
    "        # The gradient descent step, the error times the gradient times the inputs\n",
    "        del_w += error_term * x\n",
    "\n",
    "    # Update the weights here. The learning rate times the \n",
    "    # change in weights, divided by the number of records to average\n",
    "    weights += learnrate * del_w / n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
